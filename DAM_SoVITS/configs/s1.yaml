pretrained_s1: ""
data_path: "datasets/kelai.npy"
output_dir: "train"
train:
  seed: 567
  epochs: 300
  batch_size: 2
  gradient_accumulation: 4
  save_every_n_epoch: 1
  precision: 16
  gradient_clip: 1.0
  min_mask_ratio: 0.5
  max_mask_ratio: 0.8
  duration_loss_weight: 0.1
  if_save_latest: false
  if_save_every_weights: true
  half_weights_save_dir: "weights"
  exp_name: "my_gpt"
optimizer:
  lr: 0.01
  lr_init: 0.00001
  lr_end: 0.0001
  warmup_steps: 2000
  decay_steps: 40000
data:
  max_eval_sample: 8
  max_sec: 54
  num_workers: 1
  pad_val: 1024 # same with EOS in model
model:
  embedding_dim: 512
  hidden_dim: 512
  head: 8
  n_layer: 12
  dropout: 0.0
  audio_vocab_size: 1027
  output_vocab_size: 1024
  phoneme_vocab_size: 513
  SEP: 512
  EOS: 1024
  MASK: 1025
  CLS: 1026
inference:
  top_k: 5